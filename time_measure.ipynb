{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35769266-0c9f-424c-a661-b4f52e3642b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from prepare_train_val import get_split\n",
    "from dataset import RoboticsDataset\n",
    "import cv2\n",
    "from models import UNet16, LinkNet34, UNet11, UNet, AlbuNet\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import utils\n",
    "import prepare_data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from prepare_data import (original_height,\n",
    "                          original_width,\n",
    "                          h_start, w_start\n",
    "                          )\n",
    "from albumentations import Compose, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b15955c8-17c2-4cc4-9b45-4d246ac5f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import UNet11, LinkNet34, UNet, UNet16, AlbuNet\n",
    "from model1 import LinkNet34_modified\n",
    "from unetplusplus import UnetPlusPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09aacef4-06a2-4964-867e-8544777e2654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35329/4017577036.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(str(model_path))\n"
     ]
    }
   ],
   "source": [
    "model = UNet16(num_classes=1)\n",
    "model_name = 'UNet16'\n",
    "model_path = f'data/models/{model_name}/{model_name}.pt'\n",
    "problem_type = 'binary'\n",
    "\n",
    "state = torch.load(str(model_path))\n",
    "state = {key.replace('module.', ''): value for key, value in state['model'].items()}\n",
    "model.load_state_dict(state)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7361115d-f173-47ab-b624-e8e4795c2e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04085540771484375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "input_data = torch.randn(1, 3, 1024, 1280).cuda()\n",
    "\n",
    "torch.cuda.synchronize()  # 同步GPU\n",
    "start_time = time.time()\n",
    "output = model(input_data)\n",
    "torch.cuda.synchronize()  # 同步GPU\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88d3a13c-54eb-40fa-8184-22174a7d1d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      40.684ms       100.33%      40.684ms      40.684ms             1  \n",
      "                                        model_inference         5.15%       2.342ms        31.39%      14.277ms      14.277ms       0.000us         0.00%      40.551ms      40.551ms             1  \n",
      "                                      aten::convolution         1.00%     454.696us        21.62%       9.834ms     393.349us       0.000us         0.00%      32.734ms       1.309ms            25  \n",
      "                                     aten::_convolution         1.31%     597.610us        20.62%       9.379ms     375.161us       0.000us         0.00%      32.734ms       1.309ms            25  \n",
      "                                           aten::conv2d         0.34%     152.720us        19.64%       8.932ms     446.599us       0.000us         0.00%      25.465ms       1.273ms            20  \n",
      "                                aten::cudnn_convolution        12.59%       5.724ms        15.66%       7.122ms     356.090us      22.048ms        54.37%      22.048ms       1.102ms            20  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us       8.710ms        21.48%       8.710ms       1.089ms             8  \n",
      "                                 aten::conv_transpose2d         0.09%      41.692us         2.41%       1.096ms     219.231us       0.000us         0.00%       7.268ms       1.454ms             5  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us       7.226ms        17.82%       7.226ms       1.032ms             7  \n",
      "                      aten::cudnn_convolution_transpose         0.87%     393.405us         1.43%     652.448us     130.490us       6.585ms        16.24%       6.585ms       1.317ms             5  \n",
      "                                            aten::relu_         1.31%     597.762us         2.75%       1.251ms      52.111us       0.000us         0.00%       4.496ms     187.346us            24  \n",
      "                                       aten::clamp_min_         0.79%     359.919us         1.44%     652.894us      27.204us       4.496ms        11.09%       4.496ms     187.346us            24  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.496ms        11.09%       4.496ms     187.346us            24  \n",
      "                                             aten::add_         1.14%     519.489us         1.83%     831.362us      33.254us       4.100ms        10.11%       4.100ms     164.009us            25  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.100ms        10.11%       4.100ms     164.009us            25  \n",
      "void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3...         0.00%       0.000us         0.00%       0.000us       0.000us       3.512ms         8.66%       3.512ms       3.512ms             1  \n",
      "void cudnn::engines_precompiled::nchwToNhwcKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       2.930ms         7.22%       2.930ms      73.245us            40  \n",
      "_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_r...         0.00%       0.000us         0.00%       0.000us       0.000us       2.744ms         6.77%       2.744ms       1.372ms             2  \n",
      "                                              aten::cat         0.51%     229.982us         0.70%     318.802us      63.760us       2.153ms         5.31%       2.153ms     430.623us             5  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.153ms         5.31%       2.153ms     430.623us             5  \n",
      "void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s168...         0.00%       0.000us         0.00%       0.000us       0.000us       1.462ms         3.60%       1.462ms     730.896us             2  \n",
      "                                       aten::max_pool2d         0.08%      37.704us         0.74%     337.622us      67.524us       0.000us         0.00%       1.168ms     233.576us             5  \n",
      "                          aten::max_pool2d_with_indices         0.49%     221.426us         0.66%     299.918us      59.984us       1.168ms         2.88%       1.168ms     233.576us             5  \n",
      "void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us       1.168ms         2.88%       1.168ms     233.576us             5  \n",
      "void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s168...         0.00%       0.000us         0.00%       0.000us       0.000us     774.628us         1.91%     774.628us     387.314us             2  \n",
      "       _5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     404.867us         1.00%     404.867us     404.867us             1  \n",
      "void cudnn::engines_precompiled::nhwcToNchwKernel<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     349.662us         0.86%     349.662us      87.415us             4  \n",
      "void gemv2N_kernel<int, int, float, float, float, fl...         0.00%       0.000us         0.00%       0.000us       0.000us     204.946us         0.51%     204.946us     204.946us             1  \n",
      "void cudnn::engines_precompiled::scalePackedTensor_k...         0.00%       0.000us         0.00%       0.000us       0.000us     173.904us         0.43%     173.904us     173.904us             1  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     129.164us         0.32%     129.164us     129.164us             1  \n",
      "void cask__5x_cudnn::computeOffsetsKernel<false, fal...         0.00%       0.000us         0.00%       0.000us       0.000us       5.600us         0.01%       5.600us       5.600us             1  \n",
      "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us       5.057us         0.01%       5.057us       2.529us             2  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.080us         0.01%       2.080us       1.040us             2  \n",
      "                                        cudaEventRecord         0.29%     130.746us         0.29%     130.746us       5.230us       0.000us         0.00%       0.000us       0.000us            25  \n",
      "                                  cudaStreamIsCapturing         0.09%      42.230us         0.09%      42.230us       1.689us       0.000us         0.00%       0.000us       0.000us            25  \n",
      "                                  cudaStreamGetPriority         0.07%      33.682us         0.07%      33.682us       1.347us       0.000us         0.00%       0.000us       0.000us            25  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.07%      31.000us         0.07%      31.000us       1.240us       0.000us         0.00%       0.000us       0.000us            25  \n",
      "                                       cudaLaunchKernel         4.23%       1.925ms         4.23%       1.925ms      16.595us       0.000us         0.00%       0.000us       0.000us           116  \n",
      "                                    cudaPeekAtLastError         0.03%      15.848us         0.03%      15.848us       0.345us       0.000us         0.00%       0.000us       0.000us            46  \n",
      "                                        cudaMemsetAsync         0.07%      34.039us         0.07%      34.039us      11.346us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                          aten::reshape         0.20%      92.495us         0.39%     175.810us       7.032us       0.000us         0.00%       0.000us       0.000us            25  \n",
      "                                             aten::view         0.18%      83.315us         0.18%      83.315us       3.333us       0.000us         0.00%       0.000us       0.000us            25  \n",
      "                                    cudaLaunchKernelExC         0.38%     173.290us         0.38%     173.290us      10.831us       0.000us         0.00%       0.000us       0.000us            16  \n",
      "                                   cudaFuncSetAttribute         0.10%      43.320us         0.10%      43.320us       1.969us       0.000us         0.00%       0.000us       0.000us            22  \n",
      "                                  cudaDeviceSynchronize        68.61%      31.202ms        68.61%      31.202ms      31.202ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 45.479ms\n",
      "Self CUDA time total: 40.551ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(input_data)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be98034c-b161-48a5-8c35-3e106e3ecab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d24fc0-fb50-4b86-8d27-4e44b07c6d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
