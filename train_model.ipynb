{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download requirement environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "import prepare_data\n",
    "\n",
    "\n",
    "\n",
    "class RoboticsDataset(Dataset):\n",
    "    def __init__(self, file_names, to_augment=False, transform=None, mode='train', problem_type=None):\n",
    "        self.file_names = file_names\n",
    "        self.to_augment = to_augment\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.problem_type = problem_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.file_names[idx]\n",
    "        image = load_image(img_file_name)\n",
    "        mask = load_mask(img_file_name, self.problem_type)\n",
    "\n",
    "        data = {\"image\": image, \"mask\": mask}\n",
    "        augmented = self.transform(**data)\n",
    "        image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            if self.problem_type == 'binary':\n",
    "                return image, torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "            else:\n",
    "                return image, torch.tensor(mask, dtype=torch.long)\n",
    "        else:\n",
    "            return image, str(img_file_name)\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(str(path))\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def load_mask(path, problem_type):\n",
    "    if problem_type == 'binary':\n",
    "        mask_folder = 'binary_masks'\n",
    "        factor = prepare_data.binary_factor\n",
    "    elif problem_type == 'parts':\n",
    "        mask_folder = 'parts_masks'\n",
    "        factor = prepare_data.parts_factor\n",
    "    elif problem_type == 'instruments':\n",
    "        factor = prepare_data.instrument_factor\n",
    "        mask_folder = 'instruments_masks'\n",
    "\n",
    "    mask = cv2.imread(str(path).replace('images', mask_folder).replace('jpg', 'png'), 0)\n",
    "\n",
    "    return (mask / factor).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get paths of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_data import data_path\n",
    "import random\n",
    "\n",
    "def get_split(random_seeds=42):\n",
    "    random.seed(random_seeds)\n",
    "    train_path = data_path / 'cropped_train'\n",
    "    \n",
    "    train_file_names = []\n",
    "    val_file_names = []\n",
    "\n",
    "    for instrument_id in range(1, 9):\n",
    "        all_file_names = list((train_path / ('instrument_dataset_' + str(instrument_id)) / 'images').glob('*'))\n",
    "        random.shuffle(all_file_names)\n",
    "        split_idx = int(len(all_file_names) * 0.8)\n",
    "        train_file_names.extend(all_file_names[:split_idx])\n",
    "        val_file_names.extend(all_file_names[split_idx:])\n",
    "\n",
    "    return train_file_names, val_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crop_height = 1024\n",
    "train_crop_width = 1280\n",
    "val_crop_height = 1024\n",
    "val_crop_width = 1280\n",
    "workers = 12\n",
    "batch_size = 8\n",
    "problem_type = 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def make_loader(file_names, shuffle=False, transform=None, problem_type=problem_type, batch_size=1):\n",
    "        return DataLoader(\n",
    "            dataset=RoboticsDataset(file_names, transform=transform, problem_type=problem_type),\n",
    "            shuffle=shuffle,\n",
    "            num_workers=workers,\n",
    "            batch_size=batch_size,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,\n",
    "    Normalize,\n",
    "    Compose,\n",
    "    PadIfNeeded,\n",
    "    RandomCrop,\n",
    "    CenterCrop\n",
    ")\n",
    "def train_transform(p=1):\n",
    "    return Compose([\n",
    "        PadIfNeeded(min_height=train_crop_height, min_width=train_crop_width, p=1),\n",
    "        RandomCrop(height=train_crop_height, width=train_crop_width, p=1),\n",
    "        VerticalFlip(p=0.5),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        Normalize(p=1)\n",
    "    ], p=p)\n",
    "\n",
    "def val_transform(p=1):\n",
    "    return Compose([\n",
    "        PadIfNeeded(min_height=val_crop_height, min_width=val_crop_width, p=1),\n",
    "        CenterCrop(height=val_crop_height, width=val_crop_width, p=1),\n",
    "        Normalize(p=1)\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_names, val_file_names = get_split()\n",
    "train_loader = make_loader(train_file_names, shuffle=True, transform=train_transform(p=1), problem_type=problem_type,batch_size=batch_size)\n",
    "valid_loader = make_loader(val_file_names, transform=val_transform(p=1), problem_type=problem_type,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import UNet11, LinkNet34, UNet, UNet16, AlbuNet\n",
    "from torch import nn\n",
    "from unetplusplus import UnetPlusPlus\n",
    "from model1 import LinkNet34_modified\n",
    "\n",
    "model_name = 'LinkNet34_modified'\n",
    "model = LinkNet34_modified(num_classes=num_classes)\n",
    "if torch.cuda.is_available():\n",
    "    model = nn.DataParallel(model, device_ids=device_ids).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import LossBinary, LossMulti\n",
    "jaccard_weight = 0.3\n",
    "loss = LossBinary(jaccard_weight=jaccard_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "import torch.backends.cudnn\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkpoints folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'runs/debug'\n",
    "# root.joinpath('params.json').write_text(json.dumps(vars(args), indent=True, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(x):\n",
    "    return x.to('cuda', non_blocking=True) if torch.cuda.is_available() else x\n",
    "def write_event(log, step, **data):\n",
    "    data['step'] = step\n",
    "    data['dt'] = datetime.now().isoformat()\n",
    "    log.write(json.dumps(data, sort_keys=True))\n",
    "    log.write('\\n')\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, valid_loader, validation, init_optimizer, n_epochs=1, lr=0.0001, batch_size=1, fold=None,\n",
    "          num_classes=None, root='runs/debug',model_name=model_name):\n",
    "    lr = lr\n",
    "    n_epochs = n_epochs\n",
    "    optimizer = init_optimizer(lr)\n",
    "\n",
    "    root = Path(root)\n",
    "    model_path = root / f'{model_name}.pt'\n",
    "    if model_path.exists():\n",
    "        state = torch.load(str(model_path))\n",
    "        epoch = state['epoch']\n",
    "        step = state['step']\n",
    "        model.load_state_dict(state['model'])\n",
    "        print('Restored model, epoch {}, step {:,}'.format(epoch, step))\n",
    "    else:\n",
    "        epoch = 1\n",
    "        step = 0\n",
    "\n",
    "    save = lambda ep: torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'epoch': ep,\n",
    "        'step': step,\n",
    "    }, str(model_path))\n",
    "\n",
    "    report_each = 10\n",
    "    log = root.joinpath('train.log').open('at', encoding='utf8')\n",
    "    valid_losses = []\n",
    "    for epoch in range(epoch, n_epochs + 1):\n",
    "        model.train()\n",
    "        random.seed()\n",
    "        tq = tqdm.tqdm(total=(len(train_loader) * batch_size))\n",
    "        tq.set_description('Epoch {}, lr {}'.format(epoch, lr))\n",
    "        losses = []\n",
    "        tl = train_loader\n",
    "        mean_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(tl):\n",
    "            inputs = cuda(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                targets = cuda(targets)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            batch_size = inputs.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "            tq.update(batch_size)\n",
    "            losses.append(loss.item())\n",
    "            mean_loss = np.mean(losses[-report_each:])\n",
    "            tq.set_postfix(loss='{:.5f}'.format(mean_loss))\n",
    "            if i and i % report_each == 0:\n",
    "                write_event(log, step, loss=mean_loss)\n",
    "        write_event(log, step, loss=mean_loss)\n",
    "        tq.close()\n",
    "        save(epoch + 1)\n",
    "        valid_metrics = validation(model, criterion, valid_loader, num_classes)\n",
    "        write_event(log, step, **valid_metrics)\n",
    "        valid_loss = valid_metrics['valid_loss']\n",
    "        valid_losses.append(valid_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation import validation_binary, validation_multi\n",
    "valid = validation_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = lambda lr: Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, lr 0.0001:   0%|          | 0/1440 [00:00<?, ?it/s]/root/autodl-tmp/mldl/code/model1.py:92: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  out = F.upsample(out, size=(h, w), mode=\"bilinear\")\n",
      "Epoch 1, lr 0.0001: 100%|██████████| 1440/1440 [00:57<00:00, 25.10it/s, loss=0.32689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.34055, jaccard: 0.01944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.63it/s, loss=0.07962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.08544, jaccard: 0.88614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.31it/s, loss=0.06414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.07647, jaccard: 0.88744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.29it/s, loss=0.05994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.07225, jaccard: 0.89565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, lr 0.0001: 100%|██████████| 1440/1440 [00:51<00:00, 28.07it/s, loss=0.05301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.06141, jaccard: 0.91255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, lr 0.0001: 100%|██████████| 1440/1440 [00:51<00:00, 28.18it/s, loss=0.04783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05731, jaccard: 0.91692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, lr 0.0001: 100%|██████████| 1440/1440 [00:51<00:00, 28.07it/s, loss=0.03837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05533, jaccard: 0.92385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.51it/s, loss=0.04231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05828, jaccard: 0.91690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.37it/s, loss=0.04715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05566, jaccard: 0.92186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.25it/s, loss=0.04839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05194, jaccard: 0.92769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.46it/s, loss=0.03666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05118, jaccard: 0.92800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, lr 0.0001: 100%|██████████| 1440/1440 [00:50<00:00, 28.29it/s, loss=0.04460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05719, jaccard: 0.91691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, lr 0.0001: 100%|██████████| 1440/1440 [00:51<00:00, 28.04it/s, loss=0.05706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05810, jaccard: 0.91594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, lr 0.0001: 100%|██████████| 1440/1440 [00:51<00:00, 28.19it/s, loss=0.03520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05764, jaccard: 0.91368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, lr 0.0001: 100%|██████████| 1440/1440 [00:51<00:00, 28.16it/s, loss=0.03723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.05123, jaccard: 0.92908\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    criterion=loss,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    validation=valid,\n",
    "    init_optimizer=optimizer,\n",
    "    n_epochs=15,\n",
    "    lr=0.0001,\n",
    "    batch_size=batch_size,\n",
    "    num_classes=num_classes,\n",
    "    model_name = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate mask using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f'predictions/{model_name}/binary'\n",
    "workers = 12\n",
    "from prepare_data import (original_height,\n",
    "                          original_width,\n",
    "                          h_start, w_start\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transform(p=1):\n",
    "    return Compose([\n",
    "        Normalize(p=1)\n",
    "    ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "def predict(model, from_file_names, batch_size, to_path, problem_type, img_transform,workers=workers,):\n",
    "    loader = DataLoader(\n",
    "        dataset=RoboticsDataset(from_file_names, transform=img_transform, mode='predict', problem_type=problem_type),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (inputs, paths) in enumerate(tqdm.tqdm(loader, desc='Predict')):\n",
    "            inputs = cuda(inputs)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            for i, image_name in enumerate(paths):\n",
    "                if problem_type == 'binary':\n",
    "                    factor = prepare_data.binary_factor\n",
    "                    t_mask = (F.sigmoid(outputs[i, 0]).data.cpu().numpy() * factor).astype(np.uint8)\n",
    "                elif problem_type == 'parts':\n",
    "                    factor = prepare_data.parts_factor\n",
    "                    t_mask = (outputs[i].data.cpu().numpy().argmax(axis=0) * factor).astype(np.uint8)\n",
    "                elif problem_type == 'instruments':\n",
    "                    factor = prepare_data.instrument_factor\n",
    "                    t_mask = (outputs[i].data.cpu().numpy().argmax(axis=0) * factor).astype(np.uint8)\n",
    "\n",
    "                h, w = t_mask.shape\n",
    "\n",
    "                full_mask = np.zeros((original_height, original_width))\n",
    "                full_mask[h_start:h_start + h, w_start:w_start + w] = t_mask\n",
    "\n",
    "                instrument_folder = Path(paths[i]).parent.parent.name\n",
    "\n",
    "                (to_path / instrument_folder).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                cv2.imwrite(str(to_path / instrument_folder / (Path(paths[i]).stem + '.png')), full_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num file_names = 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|██████████| 90/90 [00:19<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "val_file_names\n",
    "print('num file_names = {}'.format(len(val_file_names)))\n",
    "output_path = Path(output_path)\n",
    "output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "predict(model, val_file_names, batch_size, output_path, problem_type=problem_type,img_transform=img_transform(p=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(y_true, y_pred):\n",
    "    intersection = (y_true * y_pred).sum()\n",
    "    union = y_true.sum() + y_pred.sum() - intersection\n",
    "    return (intersection + 1e-15) / (union + 1e-15)\n",
    "\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    return (2 * (y_true * y_pred).sum() + 1e-15) / (y_true.sum() + y_pred.sum() + 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from prepare_data import height, width, h_start, w_start\n",
    "\n",
    "target_path = f'predictions/{model_name}'\n",
    "train_path = 'data/cropped_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "result_dice = []\n",
    "result_jaccard = []\n",
    "if problem_type == 'binary':\n",
    "    for instrument_id in tqdm.tqdm(range(1, 9)):\n",
    "        instrument_dataset_name = 'instrument_dataset_' + str(instrument_id)\n",
    "\n",
    "        pred_folder_name = (Path(target_path) / 'binary' / instrument_dataset_name)\n",
    "        if not os.path.exists(pred_folder_name):\n",
    "            continue\n",
    "\n",
    "        for file_name in (Path(train_path) / instrument_dataset_name / 'binary_masks').glob('*'):\n",
    "            pred_file_name = (Path(target_path) / 'binary' / instrument_dataset_name / file_name.name)\n",
    "            if not os.path.exists(pred_file_name):\n",
    "                continue\n",
    "            \n",
    "            y_true = (cv2.imread(str(file_name), 0) > 0).astype(np.uint8)\n",
    "\n",
    "            pred_image = (cv2.imread(str(pred_file_name), 0) > 255 * 0.5).astype(np.uint8)\n",
    "            y_pred = pred_image[h_start:h_start + height, w_start:w_start + width]\n",
    "\n",
    "            result_dice += [dice(y_true, y_pred)]\n",
    "            result_jaccard += [jaccard(y_true, y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice =  0.9306508661052798 0.08574437766033535\n",
      "Jaccard =  0.8792055832122158 0.11364465961032456\n"
     ]
    }
   ],
   "source": [
    "print('Dice = ', np.mean(result_dice), np.std(result_dice))\n",
    "print('Jaccard = ', np.mean(result_jaccard), np.std(result_jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2458/3808355107.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(str(model_path))\n"
     ]
    }
   ],
   "source": [
    "model = LinkNet34(1)\n",
    "model_name = 'LinkNet34'\n",
    "model_path = 'data/models/LinkNet34/LinkNet34.pt'\n",
    "problem_type = 'binary'\n",
    "\n",
    "state = torch.load(str(model_path))\n",
    "state = {key.replace('module.', ''): value for key, value in state['model'].items()}\n",
    "model.load_state_dict(state)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (283474602.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[30], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    target_path =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "target_path = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
